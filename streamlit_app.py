import streamlit as st
from io import BytesIO
from pypdf import PdfReader
import re
import unicodedata
from openai import OpenAI
import json
import os
from pathlib import Path
import plotly.express as px
import pandas as pd
import csv
import io

# ìƒìˆ˜ ì •ì˜
MAX_FILE_SIZE_MB = 30
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024

# API í‚¤ ê´€ë¦¬
CONFIG_DIR = Path(__file__).parent / "config"
CONFIG_FILE = CONFIG_DIR / "api_keys.json"

def load_api_key():
    """API í‚¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return api_key
    
    try:
        if hasattr(st, 'secrets') and 'default' in st.secrets and 'openai_api_key' in st.secrets['default']:
            return st.secrets['default']['openai_api_key']
    except:
        pass
    
    try:
        if CONFIG_FILE.exists():
            with open(CONFIG_FILE, 'r') as f:
                config = json.load(f)
                return config.get('openai_api_key')
    except:
        pass
    
    return None

@st.cache_resource
def get_openai_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    api_key = load_api_key()
    if not api_key:
        return None
    return OpenAI(api_key=api_key)

# ==================== GPT ê¸°ë°˜ ë¶„ì„ í•¨ìˆ˜ ====================

def gpt_analyze_all(text, max_words=3500):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        client = get_openai_client()
        if not client:
            return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        words = text.split()
        truncated_text = ' '.join(words[:max_words])
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆì  ì—°êµ¬ë°©ë²•ë¡ ì— íŠ¹íˆ ì •í†µí•˜ë©°, í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ìƒì„¸í•œ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": f"""ë‹¤ìŒ í•™ìˆ  ë…¼ë¬¸ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

{truncated_text}

ë‹¤ìŒ ì„¹ì…˜ë³„ë¡œ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

[í•µì‹¬ìš”ì•½]
3-5ë¬¸ì¥ìœ¼ë¡œ ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½

[ì—°êµ¬ëª©ì ]
ì—°êµ¬ì˜ ëª©ì ê³¼ ë°°ê²½ ì„¤ëª…

[ì—°êµ¬ë°©ë²•]
ì‚¬ìš©ëœ ì—°êµ¬ë°©ë²•ë¡  ìƒì„¸ ì„¤ëª… (ì°¸ì—¬ì, ìë£Œìˆ˜ì§‘, ë¶„ì„ë°©ë²• í¬í•¨)

[ì£¼ìš”ë°œê²¬]
í•µì‹¬ ì—°êµ¬ ê²°ê³¼ ë° ë°œê²¬ì‚¬í•­

[ì´ë¡ ì ê¸°ì—¬]
ì´ë¡ ì /ì‹¤ì²œì  í•¨ì˜ì™€ ê¸°ì—¬

[í•œê³„ì ]
ì—°êµ¬ì˜ í•œê³„ì  ë° í–¥í›„ ì—°êµ¬ ë°©í–¥"""}
            ],
            temperature=0.3,
            max_tokens=2500
        )
        
        result = response.choices[0].message.content
        
        # ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
        sections = {}
        current_section = None
        current_content = []
        
        for line in result.split('\n'):
            if line.strip().startswith('[') and line.strip().endswith(']'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = line.strip()[1:-1]
                current_content = []
            else:
                if current_section and line.strip():
                    current_content.append(line)
        
        if current_section:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections if sections else {"í•µì‹¬ìš”ì•½": result}
        
    except Exception as e:
        return {"error": f"GPT ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def gpt_analyze_structure(text, max_words=3000):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        client = get_openai_client()
        if not client:
            return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        words = text.split()
        truncated_text = ' '.join(words[:max_words])
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. IMRaD êµ¬ì¡°(ì„œë¡ , ë°©ë²•, ê²°ê³¼, ë…¼ì˜)ë¥¼ ì˜ ì´í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤."},
                {"role": "user", "content": f"""ë‹¤ìŒ ë…¼ë¬¸ì˜ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ê° ì„¹ì…˜ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:

{truncated_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

[ì„œë¡ _ë°°ê²½]
ì„œë¡  ë° ì—°êµ¬ ë°°ê²½ ìš”ì•½ (3-5ë¬¸ì¥)

[ì´ë¡ ì _í”„ë ˆì„ì›Œí¬]
ì´ë¡ ì  í‹€ ë° ì„ í–‰ì—°êµ¬ ìš”ì•½ (3-5ë¬¸ì¥)

[ì—°êµ¬ë°©ë²•]
ì—°êµ¬ì„¤ê³„, ì°¸ì—¬ì, ìë£Œìˆ˜ì§‘ ë°©ë²• ìƒì„¸ ì„¤ëª…

[ìë£Œë¶„ì„]
ìë£Œ ë¶„ì„ ì ˆì°¨ ë° ê¸°ë²• ì„¤ëª…

[ì—°êµ¬ê²°ê³¼]
ì£¼ìš” ì—°êµ¬ ê²°ê³¼ ìš”ì•½

[ë…¼ì˜_í•¨ì˜]
ë…¼ì˜ ë° ì‹¤ì²œì  í•¨ì˜"""}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        
        result = response.choices[0].message.content
        
        # ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
        sections = {}
        current_section = None
        current_content = []
        
        for line in result.split('\n'):
            if line.strip().startswith('[') and line.strip().endswith(']'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = line.strip()[1:-1]
                current_content = []
            else:
                if current_section and line.strip():
                    current_content.append(line)
        
        if current_section:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections if sections else {"error": "êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨"}
        
    except Exception as e:
        return {"error": f"êµ¬ì¡° ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def gpt_analyze_keywords_themes(text, max_words=3000):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì œì™€ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        client = get_openai_client()
        if not client:
            return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        words = text.split()
        truncated_text = ' '.join(words[:max_words])
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ì˜ ì£¼ì œì™€ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": f"""ë‹¤ìŒ ë…¼ë¬¸ì—ì„œ ì—°êµ¬ì§ˆë¬¸, ì£¼ìš” ì£¼ì œ, í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{truncated_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

[ì—°êµ¬ì§ˆë¬¸]
- RQ1: ì²« ë²ˆì§¸ ì—°êµ¬ì§ˆë¬¸
- RQ2: ë‘ ë²ˆì§¸ ì—°êµ¬ì§ˆë¬¸
- RQ3: ì„¸ ë²ˆì§¸ ì—°êµ¬ì§ˆë¬¸

[ì—°êµ¬ê°€ì„¤]
- H1: ì²« ë²ˆì§¸ ê°€ì„¤
- H2: ë‘ ë²ˆì§¸ ê°€ì„¤

[ì£¼ìš”ì£¼ì œ]
- ì£¼ì œ1: ì²« ë²ˆì§¸ ì£¼ìš” ì£¼ì œ
- ì£¼ì œ2: ë‘ ë²ˆì§¸ ì£¼ìš” ì£¼ì œ
- ì£¼ì œ3: ì„¸ ë²ˆì§¸ ì£¼ìš” ì£¼ì œ
- ì£¼ì œ4: ë„¤ ë²ˆì§¸ ì£¼ìš” ì£¼ì œ
- ì£¼ì œ5: ë‹¤ì„¯ ë²ˆì§¸ ì£¼ìš” ì£¼ì œ

[í•µì‹¬ê°œë…]
ê°œë…1, ê°œë…2, ê°œë…3, ê°œë…4, ê°œë…5

[ì¤‘ìš”í‚¤ì›Œë“œ]
í‚¤ì›Œë“œ1, í‚¤ì›Œë“œ2, í‚¤ì›Œë“œ3, í‚¤ì›Œë“œ4, í‚¤ì›Œë“œ5, í‚¤ì›Œë“œ6, í‚¤ì›Œë“œ7, í‚¤ì›Œë“œ8, í‚¤ì›Œë“œ9, í‚¤ì›Œë“œ10

[í•™ìˆ ìš©ì–´]
ìš©ì–´1, ìš©ì–´2, ìš©ì–´3, ìš©ì–´4, ìš©ì–´5, ìš©ì–´6, ìš©ì–´7

ì£¼ì˜: ì—°êµ¬ì§ˆë¬¸ì´ë‚˜ ê°€ì„¤ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš°, ë…¼ë¬¸ì˜ ëª©ì ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”."""}
            ],
            temperature=0.3,
            max_tokens=1500
        )
        
        result = response.choices[0].message.content
        
        # ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
        sections = {}
        current_section = None
        current_content = []
        
        for line in result.split('\n'):
            if line.strip().startswith('[') and line.strip().endswith(']'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = line.strip()[1:-1]
                current_content = []
            else:
                if current_section and line.strip():
                    current_content.append(line)
        
        if current_section:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections if sections else {"error": "ì£¼ì œ ë¶„ì„ ì‹¤íŒ¨"}
        
    except Exception as e:
        return {"error": f"ì£¼ì œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

def gpt_analyze_references(text):
    """GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¸ê³ ë¬¸í—Œì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        client = get_openai_client()
        if not client:
            return {"error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        # References ì„¹ì…˜ ì°¾ê¸° - ë” ë„“ì€ ë²”ìœ„ë¡œ ê²€ìƒ‰
        ref_section = ""
        patterns = [
            r'References\s*\n(.*?)(?=\n\n[A-Z][a-z]+|\Z)',
            r'REFERENCES\s*\n(.*?)(?=\n\n[A-Z][a-z]+|\Z)',
            r'Bibliography\s*\n(.*?)(?=\n\n[A-Z][a-z]+|\Z)',
            r'ì°¸ê³ ë¬¸í—Œ\s*\n(.*?)(?=\n\n|\Z)',
            r'References\s+(.*)',
            r'REFERENCES\s+(.*)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
            if match:
                ref_section = match.group(1)[:8000]  # ë” ë§ì€ í…ìŠ¤íŠ¸ í¬í•¨
                break
        
        # ì°¸ê³ ë¬¸í—Œì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ëë¶€ë¶„ ì‚¬ìš©
        if not ref_section or len(ref_section) < 200:
            # í…ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ 20% ì‚¬ìš©
            last_part = text[int(len(text) * 0.8):]
            if len(last_part) > 500:
                ref_section = last_part[:8000]
        
        if not ref_section or len(ref_section) < 200:
            return {"error": "ì°¸ê³ ë¬¸í—Œ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë…¼ë¬¸ì— ì°¸ê³ ë¬¸í—Œì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."}
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ í•™ìˆ  ë…¼ë¬¸ì˜ ì°¸ê³ ë¬¸í—Œì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„œì§€ì •ë³´ë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ê³  ëŒ€í•™ì›ìƒì—ê²Œ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": f"""ë‹¤ìŒ ì°¸ê³ ë¬¸í—Œ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ ëŒ€í•™ì›ìƒì´ ë¬¸í—Œ ì¡°ì‚¬ì— í™œìš©í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸íˆ ì •ë¦¬í•´ì£¼ì„¸ìš”:

{ref_section}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

[í†µê³„ìš”ì•½]
â€¢ ì´ ì°¸ê³ ë¬¸í—Œ: XXê°œ
â€¢ ì—°ë„ ë²”ìœ„: XXXX-XXXXë…„
â€¢ ìµœê·¼ 5ë…„ ì´ë‚´: XXê°œ (XX%)
â€¢ í‰ê·  ì €ììˆ˜: X.Xëª…

[í•µì‹¬ë¬¸í—Œ]
ê° ë¬¸í—Œì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´ (ìµœëŒ€ 8ê°œ):
â€¢ ì €ì(ì—°ë„). ì œëª©. ì €ë„/ì¶œíŒì‚¬. (í”¼ì¸ìš© íšŸìˆ˜ê°€ ë§ê±°ë‚˜ í•µì‹¬ì ì¸ ë¬¸í—Œ ìœ„ì£¼)

[ì£¼ìš”ì €ë„]
â€¢ Journal Name 1 (XXíšŒ ì¸ìš©)
â€¢ Journal Name 2 (XXíšŒ ì¸ìš©)
â€¢ Journal Name 3 (XXíšŒ ì¸ìš©)

[ì˜í–¥ë ¥ìˆëŠ”ì—°êµ¬ì]
â€¢ ì—°êµ¬ì1 (XXíšŒ ì¸ìš©) - ì£¼ìš” ì—°êµ¬ ì£¼ì œ
â€¢ ì—°êµ¬ì2 (XXíšŒ ì¸ìš©) - ì£¼ìš” ì—°êµ¬ ì£¼ì œ
â€¢ ì—°êµ¬ì3 (XXíšŒ ì¸ìš©) - ì£¼ìš” ì—°êµ¬ ì£¼ì œ

[ì¶œíŒë¬¼ìœ í˜•]
â€¢ ì €ë„ë…¼ë¬¸: XXê°œ
â€¢ ë‹¨í–‰ë³¸/ì €ì„œ: XXê°œ
â€¢ í•™ìˆ ëŒ€íšŒ: XXê°œ
â€¢ í•™ìœ„ë…¼ë¬¸: XXê°œ
â€¢ ê¸°íƒ€: XXê°œ

[ì‹œì‚¬ì ]
ì´ ì°¸ê³ ë¬¸í—Œ ëª©ë¡ì´ ë³´ì—¬ì£¼ëŠ” ì—°êµ¬ íë¦„, ì£¼ìš” ì´ë¡ ì  ê¸°ë°˜, ë˜ëŠ” ì—°êµ¬ë°©ë²•ë¡ ì  íŠ¹ì§•ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½"""}
            ],
            temperature=0.2,
            max_tokens=2000
        )
        
        result = response.choices[0].message.content
        
        # ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
        sections = {}
        current_section = None
        current_content = []
        
        for line in result.split('\n'):
            if line.strip().startswith('[') and line.strip().endswith(']'):
                if current_section:
                    sections[current_section] = '\n'.join(current_content).strip()
                current_section = line.strip()[1:-1]
                current_content = []
            else:
                if current_section and line.strip():
                    current_content.append(line)
        
        if current_section:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections if sections else {"error": "ì°¸ê³ ë¬¸í—Œ ë¶„ì„ ì‹¤íŒ¨"}
        
    except Exception as e:
        return {"error": f"ì°¸ê³ ë¬¸í—Œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}

# ê³ ê¸‰ë¶„ì„ ë° ë¹„êµë¶„ì„ ê¸°ëŠ¥ ì œê±°ë¨ (ì•ˆì •ì„± í–¥ìƒì„ ìœ„í•´)
# í•µì‹¬ ë¶„ì„ ê¸°ëŠ¥ì—ë§Œ ì§‘ì¤‘: ì¢…í•©ë¶„ì„, êµ¬ì¡°ë¶„ì„, ì£¼ì œ&í‚¤ì›Œë“œ ë¶„ì„, ì°¸ê³ ë¬¸í—Œ ë¶„ì„

# ==================== í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ====================
def clean_text(text):
    """í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ê³  ì •ê·œí™”í•©ë‹ˆë‹¤."""
    text = unicodedata.normalize('NFKD', text)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', text)
    return text.strip()

# ==================== PDF ë¡œë“œ ====================
def load_pdf_from_upload(uploaded_file):
    """ì—…ë¡œë“œëœ PDF íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        file_size = uploaded_file.size
        file_size_mb = file_size / 1024 / 1024
        
        if file_size == 0:
            return None, "âŒ ì—…ë¡œë“œëœ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
        
        if file_size > MAX_FILE_SIZE_BYTES:
            return None, f"âŒ íŒŒì¼ í¬ê¸°ê°€ {MAX_FILE_SIZE_MB}MBë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤.\ní˜„ì¬ íŒŒì¼: {file_size_mb:.2f}MB\n\nğŸ’¡ PDF ì••ì¶•ì„ ê¶Œì¥í•©ë‹ˆë‹¤: smallpdf.com"
        
        if file_size_mb > 20:
            st.warning(f"âš ï¸ íŒŒì¼ í¬ê¸°ê°€ {file_size_mb:.2f}MBì…ë‹ˆë‹¤. ì²˜ë¦¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        uploaded_file.seek(0)
        content = BytesIO(uploaded_file.read())
        content.seek(0)
        
        header = content.read(4)
        content.seek(0)
        if header != b'%PDF':
            return None, "âŒ ìœ íš¨í•œ PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤."
        
        return content, None
    except Exception as e:
        return None, f"âŒ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"

# ==================== í…ìŠ¤íŠ¸ ì¶”ì¶œ ====================
def extract_text(pdf_file):
    """PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ë©”íƒ€ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    try:
        pdf_file.seek(0)
        reader = PdfReader(pdf_file)
        
        if len(reader.pages) == 0:
            return None, None, "âŒ PDF íŒŒì¼ì— í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        metadata = {
            'pages': len(reader.pages),
            'title': None,
            'author': None,
            'subject': None,
            'creator': None
        }
        
        if reader.metadata:
            metadata['title'] = reader.metadata.get('/Title', None)
            metadata['author'] = reader.metadata.get('/Author', None)
            metadata['subject'] = reader.metadata.get('/Subject', None)
            metadata['creator'] = reader.metadata.get('/Creator', None)
        
        text = ""
        for i, page in enumerate(reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n\n"
            except Exception as e:
                continue
        
        if not text or len(text.strip()) < 100:
            return None, None, "âŒ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ê¸°ë°˜ PDFì´ê±°ë‚˜ ë³´í˜¸ëœ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        text = clean_text(text)
        return text, metadata, None
        
    except Exception as e:
        error_msg = str(e)
        if "empty file" in error_msg.lower():
            return None, None, "âŒ ë¹ˆ íŒŒì¼ì´ê±°ë‚˜ ì†ìƒëœ PDFì…ë‹ˆë‹¤."
        elif "encrypted" in error_msg.lower():
            return None, None, "âŒ ì•”í˜¸í™”ëœ PDFì…ë‹ˆë‹¤."
        else:
            return None, None, f"âŒ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {error_msg}"

# ==================== Streamlit UI ====================
def main():
    st.set_page_config(
        page_title="AI í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ë„êµ¬",
        page_icon="ğŸ“š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: 700;
            color: #1f77b4;
            margin-bottom: 0.5rem;
        }
        .sub-header {
            font-size: 1.1rem;
            color: #666;
            margin-bottom: 2rem;
        }
        .section-header {
            color: #1f77b4;
            border-bottom: 2px solid #1f77b4;
            padding-bottom: 0.5rem;
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        </style>
    """, unsafe_allow_html=True)
    
    st.markdown('<div class="main-header">ğŸ“š AI í•™ìˆ  ë…¼ë¬¸ ë¶„ì„ ë„êµ¬</div>', unsafe_allow_html=True)
    st.markdown('<div class="sub-header">AI ê¸°ë°˜ ëŒ€í•™ì›ìƒì„ ìœ„í•œ ì§€ëŠ¥í˜• í•™ìˆ ë…¼ë¬¸ ë¶„ì„ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)
    
    if 'papers' not in st.session_state:
        st.session_state.papers = {}
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ğŸ“¤ PDF ì—…ë¡œë“œ")
        
        with st.expander("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ", expanded=False):
            st.markdown("""
            **ğŸ¤– AI ê¸°ë°˜ ë¶„ì„ ê¸°ëŠ¥:**
            - AI ì¢…í•© ë¶„ì„ (ìš”ì•½, ì£¼ì œ, í‚¤ì›Œë“œ)
            - êµ¬ì¡° ë¶„ì„ (ì„œë¡ , ë°©ë²•, ê²°ê³¼, ë…¼ì˜)
            - ì°¸ê³ ë¬¸í—Œ ì‹¬ì¸µ ë¶„ì„
            - ê³ ê¸‰ í…ìŠ¤íŠ¸ ë¶„ì„ (ê°€ë…ì„±, ë‹´í™” êµ¬ì¡°)
            - ë‹¤ì¤‘ ë…¼ë¬¸ ë¹„êµ ë¶„ì„
            
            **ğŸ“ íŒŒì¼ í¬ê¸°:**
            - ê¶Œì¥: 10MB ì´í•˜
            - ìµœëŒ€: 30MB
            - 20MB ì´ìƒ: ì••ì¶• ê¶Œì¥
            
            **ğŸ’¡ ëª¨ë“  ë¶„ì„ì´ AIë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.**
            """)
        
        st.markdown(f"**ğŸ“Š íŒŒì¼ í¬ê¸° ì œí•œ: {MAX_FILE_SIZE_MB}MB**")
        st.caption("âš ï¸ 20MB ì´ìƒ íŒŒì¼ì€ PDF ì••ì¶•ì„ ê¶Œì¥í•©ë‹ˆë‹¤. (smallpdf.com)")
        
        uploaded_file = st.file_uploader(
            "PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”",
            type=['pdf'],
            help=f"í•™ìˆ  ë…¼ë¬¸ PDF íŒŒì¼ (ìµœëŒ€: {MAX_FILE_SIZE_MB}MB)"
        )
        
        paper_name = st.text_input(
            "ë…¼ë¬¸ ì œëª© (ì„ íƒì‚¬í•­)",
            placeholder="ì˜ˆ: Smith et al. (2023)",
            help="ë¹„ì›Œë‘ë©´ íŒŒì¼ëª…ì´ ì‚¬ìš©ë©ë‹ˆë‹¤"
        )
        
        analyze_button = st.button("ğŸ” AI ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True)
        
        if analyze_button:
            if not uploaded_file:
                st.error("âŒ PDF íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            elif not load_api_key():
                st.error("âŒ OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("ğŸ“„ PDF ì²˜ë¦¬ ì¤‘..."):
                    pdf_content, error = load_pdf_from_upload(uploaded_file)
                    
                    if error:
                        st.error(error)
                    else:
                        with st.spinner("ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
                            text, metadata, extract_error = extract_text(pdf_content)
                            
                            if extract_error:
                                st.error(extract_error)
                            else:
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                
                                status_text.text("ğŸ¤– AI ì¢…í•© ë¶„ì„ ì¤‘...")
                                progress_bar.progress(20)
                                main_analysis = gpt_analyze_all(text)
                                
                                status_text.text("ğŸ¤– AI êµ¬ì¡° ë¶„ì„ ì¤‘...")
                                progress_bar.progress(40)
                                structure = gpt_analyze_structure(text)
                                
                                status_text.text("ğŸ¤– AI ì£¼ì œ&í‚¤ì›Œë“œ ë¶„ì„ ì¤‘...")
                                progress_bar.progress(60)
                                keywords_themes = gpt_analyze_keywords_themes(text)
                                
                                status_text.text("ğŸ¤– AI ì°¸ê³ ë¬¸í—Œ ë¶„ì„ ì¤‘...")
                                progress_bar.progress(80)
                                references = gpt_analyze_references(text)
                                
                                name = paper_name.strip() if paper_name.strip() else uploaded_file.name.replace('.pdf', '')
                                st.session_state.papers[name] = {
                                    'text': text,
                                    'metadata': metadata,
                                    'main_analysis': main_analysis,
                                    'structure': structure,
                                    'keywords_themes': keywords_themes,
                                    'references': references
                                }
                                
                                progress_bar.progress(100)
                                status_text.text("âœ… AI ë¶„ì„ ì™„ë£Œ!")
                                st.success(f"**'{name}'** ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                                st.balloons()
        
        # ë¡œë“œëœ ë…¼ë¬¸ ëª©ë¡
        if st.session_state.papers:
            st.markdown("---")
            st.subheader("ğŸ“š ë¶„ì„ëœ ë…¼ë¬¸")
            
            for idx, name in enumerate(st.session_state.papers.keys(), 1):
                col1, col2 = st.columns([4, 1])
                with col1:
                    pages = st.session_state.papers[name]['metadata']['pages']
                    st.write(f"**{idx}.** {name}")
                    if pages:
                        st.caption(f"ğŸ“„ {pages} í˜ì´ì§€")
                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"del_{name}"):
                        del st.session_state.papers[name]
                        st.rerun()
            
            if len(st.session_state.papers) > 1:
                st.info(f"ğŸ’¡ {len(st.session_state.papers)}ê°œ ë…¼ë¬¸ ë¹„êµ ê°€ëŠ¥")
    
    # ë©”ì¸ ì˜ì—­
    if not st.session_state.papers:
        st.info("ğŸ‘ˆ **ì‹œì‘í•˜ê¸°:** ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  AI ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("### ğŸ¤– AI ì¢…í•© ë¶„ì„")
            st.write("AIê°€ ë…¼ë¬¸ì„ ì½ê³  í•µì‹¬ ë‚´ìš©, ì£¼ì œ, í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
        with col2:
            st.markdown("### ğŸ“Š êµ¬ì¡° ë¶„ì„")
            st.write("ì„œë¡ , ë°©ë²•, ê²°ê³¼, ë…¼ì˜ ë“± ë…¼ë¬¸ êµ¬ì¡°ë¥¼ AIê°€ ë¶„ì„í•©ë‹ˆë‹¤.")
        with col3:
            st.markdown("### ğŸ“š ì°¸ê³ ë¬¸í—Œ ë¶„ì„")
            st.write("AIê°€ ì°¸ê³ ë¬¸í—Œì„ ë¶„ì„í•˜ì—¬ ì—°êµ¬ ë™í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤.")
        
        st.markdown("---")
        st.markdown('<p style="text-align: center; color: #888; font-size: 0.85rem; margin-top: 2rem;">ë³¸ ë¶„ì„ ë„êµ¬ëŠ” GPT-4ë¥¼ í™œìš©í•˜ì—¬ í•™ìˆ  ë…¼ë¬¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.</p>', unsafe_allow_html=True)
    
    else:
        # ë…¼ë¬¸ ì„ íƒ ë° CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        col1, col2 = st.columns([3, 1])
        with col1:
            selected_paper = st.selectbox(
                "ğŸ“– ë¶„ì„í•  ë…¼ë¬¸ ì„ íƒ",
                options=list(st.session_state.papers.keys()),
                key="paper_selector"
            )
        
        data = st.session_state.papers[selected_paper]
        meta = data['metadata']
        
        # CSV ë°ì´í„° ìƒì„± í•¨ìˆ˜
        def generate_csv_data():
            csv_rows = []
            
            # ë©”íƒ€ë°ì´í„°
            csv_rows.append(['=== ë¬¸ì„œ ì •ë³´ ===', ''])
            csv_rows.append(['ë…¼ë¬¸ëª…', selected_paper])
            csv_rows.append(['ì œëª©', meta.get('title', '')])
            csv_rows.append(['ì €ì', meta.get('author', '')])
            csv_rows.append(['í˜ì´ì§€ ìˆ˜', str(meta.get('pages', ''))])
            csv_rows.append(['ì‘ì„± ë„êµ¬', meta.get('creator', '')])
            csv_rows.append(['', ''])
            
            # ì¢…í•© ë¶„ì„
            analysis = data.get('main_analysis', {})
            if analysis and 'error' not in analysis:
                csv_rows.append(['=== ì¢…í•© ë¶„ì„ ===', ''])
                for key, value in analysis.items():
                    csv_rows.append([key, value.replace('\n', ' ') if value else ''])
                csv_rows.append(['', ''])
            
            # êµ¬ì¡° ë¶„ì„
            structure = data.get('structure', {})
            if structure and 'error' not in structure:
                csv_rows.append(['=== êµ¬ì¡° ë¶„ì„ ===', ''])
                for key, value in structure.items():
                    csv_rows.append([key, value.replace('\n', ' ') if value else ''])
                csv_rows.append(['', ''])
            
            # ì£¼ì œ & í‚¤ì›Œë“œ
            keywords_themes = data.get('keywords_themes', {})
            if keywords_themes and 'error' not in keywords_themes:
                csv_rows.append(['=== ì£¼ì œ & í‚¤ì›Œë“œ ===', ''])
                for key, value in keywords_themes.items():
                    csv_rows.append([key, value.replace('\n', ' | ') if value else ''])
                csv_rows.append(['', ''])
            
            # ì°¸ê³ ë¬¸í—Œ
            references = data.get('references', {})
            if references and 'error' not in references:
                csv_rows.append(['=== ì°¸ê³ ë¬¸í—Œ ë¶„ì„ ===', ''])
                for key, value in references.items():
                    csv_rows.append([key, value.replace('\n', ' | ') if value else ''])
            
            # CSV ë¬¸ìì—´ ìƒì„±
            output = io.StringIO()
            writer = csv.writer(output)
            writer.writerows(csv_rows)
            return output.getvalue().encode('utf-8-sig')  # BOM ì¶”ê°€ë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€
        
        with col2:
            csv_data = generate_csv_data()
            st.download_button(
                label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_data,
                file_name=f"{selected_paper}_ë¶„ì„ê²°ê³¼.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        if meta['title'] or meta['author']:
            with st.expander("ğŸ“‹ ë¬¸ì„œ ì •ë³´", expanded=False):
                cols = st.columns(4)
                if meta['title']:
                    cols[0].metric("ì œëª©", meta['title'][:50] + "..." if len(meta['title']) > 50 else meta['title'])
                if meta['author']:
                    cols[1].metric("ì €ì", meta['author'][:30] + "..." if len(meta['author']) > 30 else meta['author'])
                if meta['pages']:
                    cols[2].metric("í˜ì´ì§€", meta['pages'])
                if meta['creator']:
                    cols[3].metric("ì‘ì„± ë„êµ¬", meta['creator'][:30] if meta['creator'] else 'N/A')
        
        tabs = st.tabs([
            "ğŸ¤– ì¢…í•© ë¶„ì„",
            "ğŸ“Š êµ¬ì¡° ë¶„ì„",
            "ğŸ¯ ì£¼ì œ & í‚¤ì›Œë“œ",
            "ğŸ“š ì°¸ê³ ë¬¸í—Œ"
        ])
        
        # íƒ­ 1: ì¢…í•© ë¶„ì„
        with tabs[0]:
            st.markdown('<div class="section-header">ğŸ¤– AI ì¢…í•© ë¶„ì„</div>', unsafe_allow_html=True)
            
            analysis = data.get('main_analysis', {})
            
            if 'error' in analysis:
                st.error(analysis['error'])
            else:
                # í•µì‹¬ìš”ì•½ - ë” ëˆˆì— ë„ê²Œ í‘œì‹œ
                if 'í•µì‹¬ìš”ì•½' in analysis and analysis['í•µì‹¬ìš”ì•½']:
                    st.markdown("### ğŸ“ í•µì‹¬ ìš”ì•½")
                    st.markdown(f"""<div style="background-color: #e8f4f8; padding: 20px; border-radius: 10px; border-left: 5px solid #1f77b4;">
                    <h4 style="margin-top: 0;">ìš”ì•½</h4>
                    <p style="font-size: 16px; line-height: 1.6;">{analysis['í•µì‹¬ìš”ì•½']}</p>
                    </div>""", unsafe_allow_html=True)
                    st.markdown("---")
                
                # 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'ì—°êµ¬ëª©ì ' in analysis and analysis['ì—°êµ¬ëª©ì ']:
                        st.markdown("### ğŸ¯ ì—°êµ¬ ëª©ì ")
                        st.markdown(f"<div style='padding: 15px; background-color: #f0f8ff; border-radius: 8px;'>{analysis['ì—°êµ¬ëª©ì ']}</div>", unsafe_allow_html=True)
                        st.markdown("")
                    
                    if 'ì—°êµ¬ë°©ë²•' in analysis and analysis['ì—°êµ¬ë°©ë²•']:
                        st.markdown("### ğŸ”¬ ì—°êµ¬ ë°©ë²•")
                        st.markdown(f"<div style='padding: 15px; background-color: #f5f5f5; border-radius: 8px;'>{analysis['ì—°êµ¬ë°©ë²•']}</div>", unsafe_allow_html=True)
                        st.markdown("")
                    
                    if 'ì´ë¡ ì ê¸°ì—¬' in analysis and analysis['ì´ë¡ ì ê¸°ì—¬']:
                        st.markdown("### ğŸ’¡ ì´ë¡ ì  ê¸°ì—¬")
                        st.markdown(f"<div style='padding: 15px; background-color: #fff8dc; border-radius: 8px;'>{analysis['ì´ë¡ ì ê¸°ì—¬']}</div>", unsafe_allow_html=True)
                
                with col2:
                    if 'ì£¼ìš”ë°œê²¬' in analysis and analysis['ì£¼ìš”ë°œê²¬']:
                        st.markdown("### ğŸ” ì£¼ìš” ë°œê²¬")
                        st.markdown(f"<div style='padding: 15px; background-color: #f0fff0; border-radius: 8px;'>{analysis['ì£¼ìš”ë°œê²¬']}</div>", unsafe_allow_html=True)
                        st.markdown("")
                    
                    if 'ì‹¤ë¬´ì ì‹œì‚¬ì ' in analysis and analysis['ì‹¤ë¬´ì ì‹œì‚¬ì ']:
                        st.markdown("### ğŸ“Š ì‹¤ë¬´ì  ì‹œì‚¬ì ")
                        st.markdown(f"<div style='padding: 15px; background-color: #fffacd; border-radius: 8px;'>{analysis['ì‹¤ë¬´ì ì‹œì‚¬ì ']}</div>", unsafe_allow_html=True)
                        st.markdown("")
                    
                    if 'í•œê³„ì ' in analysis and analysis['í•œê³„ì ']:
                        st.markdown("### âš ï¸ ì—°êµ¬ í•œê³„ ë° í–¥í›„ ë°©í–¥")
                        st.markdown(f"<div style='padding: 15px; background-color: #ffe4e1; border-radius: 8px;'>{analysis['í•œê³„ì ']}</div>", unsafe_allow_html=True)
        
        # íƒ­ 2: êµ¬ì¡° ë¶„ì„
        with tabs[1]:
            st.markdown('<div class="section-header">ğŸ“Š ë…¼ë¬¸ êµ¬ì¡° ë¶„ì„</div>', unsafe_allow_html=True)
            
            structure = data.get('structure', {})
            
            if 'error' in structure:
                st.error(structure['error'])
            else:
                # ê° ì„¹ì…˜ í‘œì‹œ
                sections = [
                    ("ì„œë¡ _ë°°ê²½", "ğŸ“– ì„œë¡  ë° ë°°ê²½", "#e8f4f8"),
                    ("ì´ë¡ ì _í”„ë ˆì„ì›Œí¬", "ğŸ“ ì´ë¡ ì  í”„ë ˆì„ì›Œí¬", "#f0f8ff"),
                    ("ì—°êµ¬ë°©ë²•", "ğŸ”¬ ì—°êµ¬ë°©ë²•", "#f5f5f5"),
                    ("ìë£Œë¶„ì„", "ğŸ“Š ìë£Œë¶„ì„ ë°©ë²•", "#fff8dc"),
                    ("ì—°êµ¬ê²°ê³¼", "ğŸ” ì£¼ìš” ì—°êµ¬ê²°ê³¼", "#f0fff0"),
                    ("ë…¼ì˜_í•¨ì˜", "ğŸ’¬ ë…¼ì˜ ë° í•¨ì˜", "#fffacd")
                ]
                
                for key, title, bg_color in sections:
                    if key in structure and structure[key]:
                        st.markdown(f"### {title}")
                        st.markdown(f"""<div style="padding: 15px; background-color: {bg_color}; border-radius: 8px; margin-bottom: 15px;">
                        {structure[key]}
                        </div>""", unsafe_allow_html=True)
        
        # íƒ­ 3: ì£¼ì œ & í‚¤ì›Œë“œ
        with tabs[2]:
            st.markdown('<div class="section-header">ğŸ¯ ì£¼ì œ & í‚¤ì›Œë“œ ë¶„ì„</div>', unsafe_allow_html=True)
            
            keywords_themes = data.get('keywords_themes', {})
            
            if 'error' in keywords_themes:
                st.error(keywords_themes['error'])
            else:
                # ì—°êµ¬ì§ˆë¬¸
                if 'ì—°êµ¬ì§ˆë¬¸' in keywords_themes and keywords_themes['ì—°êµ¬ì§ˆë¬¸']:
                    st.markdown("### â“ ì—°êµ¬ì§ˆë¬¸")
                    rqs = keywords_themes['ì—°êµ¬ì§ˆë¬¸'].strip().split('\n')
                    for rq in rqs:
                        rq = rq.strip()
                        if rq and (rq.startswith('â€¢') or rq.startswith('-') or rq.startswith('*')):
                            rq = rq[1:].strip()
                        if rq:
                            st.markdown(f"""<div style="padding: 10px; background-color: #e8f4f8; border-left: 4px solid #1f77b4; margin-bottom: 8px; border-radius: 5px;">
                            <b>RQ:</b> {rq}
                            </div>""", unsafe_allow_html=True)
                    st.markdown("---")
                
                # ì—°êµ¬ê°€ì„¤
                if 'ì—°êµ¬ê°€ì„¤' in keywords_themes and keywords_themes['ì—°êµ¬ê°€ì„¤']:
                    st.markdown("### ğŸ’­ ì—°êµ¬ê°€ì„¤")
                    hyps = keywords_themes['ì—°êµ¬ê°€ì„¤'].strip().split('\n')
                    for hyp in hyps:
                        hyp = hyp.strip()
                        if hyp and (hyp.startswith('â€¢') or hyp.startswith('-') or hyp.startswith('*')):
                            hyp = hyp[1:].strip()
                        if hyp:
                            st.markdown(f"""<div style="padding: 10px; background-color: #f0f8ff; border-left: 4px solid #4682b4; margin-bottom: 8px; border-radius: 5px;">
                            <b>H:</b> {hyp}
                            </div>""", unsafe_allow_html=True)
                    st.markdown("---")
                
                # ì£¼ìš”ì£¼ì œ
                if 'ì£¼ìš”ì£¼ì œ' in keywords_themes and keywords_themes['ì£¼ìš”ì£¼ì œ']:
                    st.markdown("### ğŸ·ï¸ ì£¼ìš” ì£¼ì œ")
                    themes = [t.strip() for t in keywords_themes['ì£¼ìš”ì£¼ì œ'].strip().split('\n') if t.strip()]
                    # ë¶ˆë¦¿ ë§ˆí¬ ì œê±°
                    themes = [t[1:].strip() if t.startswith(('â€¢', '-', '*')) else t for t in themes]
                    
                    cols = st.columns(min(3, len(themes)))
                    for i, theme in enumerate(themes):
                        if theme:
                            cols[i % len(cols)].markdown(f"""<div style="padding: 15px; background-color: #fff8dc; border-radius: 8px; text-align: center; height: 100px; display: flex; align-items: center; justify-content: center;">
                            <b>{theme}</b>
                            </div>""", unsafe_allow_html=True)
                    st.markdown("---")
                
                # í•µì‹¬ê°œë… & ì¤‘ìš”í‚¤ì›Œë“œ 2ì»¬ëŸ¼
                col1, col2 = st.columns(2)
                
                with col1:
                    if 'í•µì‹¬ê°œë…' in keywords_themes and keywords_themes['í•µì‹¬ê°œë…']:
                        st.markdown("### ğŸ§© í•µì‹¬ ê°œë…")
                        concepts = [c.strip() for c in keywords_themes['í•µì‹¬ê°œë…'].replace(',', '\n').split('\n') if c.strip()]
                        concepts = [c[1:].strip() if c.startswith(('â€¢', '-', '*')) else c for c in concepts]
                        for i, concept in enumerate(concepts[:10], 1):
                            if concept:
                                st.markdown(f"`{i}.` **{concept}**")
                
                with col2:
                    if 'ì¤‘ìš”í‚¤ì›Œë“œ' in keywords_themes and keywords_themes['ì¤‘ìš”í‚¤ì›Œë“œ']:
                        st.markdown("### ğŸ”‘ ì¤‘ìš” í‚¤ì›Œë“œ")
                        keywords = [k.strip() for k in keywords_themes['ì¤‘ìš”í‚¤ì›Œë“œ'].replace(',', '\n').split('\n') if k.strip()]
                        keywords = [k[1:].strip() if k.startswith(('â€¢', '-', '*')) else k for k in keywords]
                        for i, keyword in enumerate(keywords[:10], 1):
                            if keyword:
                                st.markdown(f"`{i}.` **{keyword}**")
                
                # í•™ìˆ ìš©ì–´
                if 'í•™ìˆ ìš©ì–´' in keywords_themes and keywords_themes['í•™ìˆ ìš©ì–´']:
                    st.markdown("---")
                    st.markdown("### ğŸ“ í•™ìˆ  ìš©ì–´")
                    terms = [t.strip() for t in keywords_themes['í•™ìˆ ìš©ì–´'].replace(',', '\n').split('\n') if t.strip()]
                    terms = [t[1:].strip() if t.startswith(('â€¢', '-', '*')) else t for t in terms]
                    st.markdown(" â€¢ ".join(terms[:15]))
        
        # íƒ­ 4: ì°¸ê³ ë¬¸í—Œ
        with tabs[3]:
            st.markdown('<div class="section-header">ğŸ“š ì°¸ê³ ë¬¸í—Œ ë¶„ì„</div>', unsafe_allow_html=True)
            
            refs = data.get('references', {})
            
            if 'error' in refs:
                st.warning(refs.get('error', 'ì°¸ê³ ë¬¸í—Œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'))
            else:
                # í†µê³„ìš”ì•½
                if 'í†µê³„ìš”ì•½' in refs and refs['í†µê³„ìš”ì•½']:
                    st.markdown("### ğŸ“Š í†µê³„ ìš”ì•½")
                    st.markdown(f"""<div style="padding: 15px; background-color: #f0f8ff; border-radius: 8px; margin-bottom: 20px;">
                    {refs['í†µê³„ìš”ì•½'].replace(chr(10), '<br>')}
                    </div>""", unsafe_allow_html=True)
                
                # í•µì‹¬ë¬¸í—Œ (ê°€ì¥ ì¤‘ìš”!)
                if 'í•µì‹¬ë¬¸í—Œ' in refs and refs['í•µì‹¬ë¬¸í—Œ']:
                    st.markdown("### ğŸ“– í•µì‹¬ ë¬¸í—Œ (í•„ë…)")
                    st.markdown("""<div style="background-color: #fffacd; padding: 10px; border-radius: 5px; margin-bottom: 10px;">
                    ğŸ’¡ <b>ì—°êµ¬ì— ê°€ì¥ ì¤‘ìš”í•œ ì°¸ê³ ë¬¸í—Œë“¤ì…ë‹ˆë‹¤. ë¬¸í—Œ ì¡°ì‚¬ ì‹œ ìš°ì„ ì ìœ¼ë¡œ ì½ì–´ë³´ì„¸ìš”.</b>
                    </div>""", unsafe_allow_html=True)
                    
                    core_refs = [r.strip() for r in refs['í•µì‹¬ë¬¸í—Œ'].strip().split('\n') if r.strip()]
                    core_refs = [r[1:].strip() if r.startswith(('â€¢', '-', '*')) else r for r in core_refs]
                    
                    for i, ref in enumerate(core_refs, 1):
                        if ref:
                            st.markdown(f"""<div style="padding: 12px; background-color: #ffffff; border-left: 4px solid #4CAF50; margin-bottom: 10px; border-radius: 5px; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
                            <b style="color: #4CAF50;">[{i}]</b> {ref}
                            </div>""", unsafe_allow_html=True)
                    st.markdown("---")
                
                # 2ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
                col1, col2 = st.columns(2)
                
                with col1:
                    # ì£¼ìš”ì €ë„
                    if 'ì£¼ìš”ì €ë„' in refs and refs['ì£¼ìš”ì €ë„']:
                        st.markdown("### ğŸ“° ì£¼ìš” ì €ë„")
                        journals = [j.strip() for j in refs['ì£¼ìš”ì €ë„'].strip().split('\n') if j.strip()]
                        journals = [j[1:].strip() if j.startswith(('â€¢', '-', '*')) else j for j in journals]
                        for journal in journals[:5]:
                            if journal:
                                st.markdown(f"â€¢ {journal}")
                        st.markdown("")
                    
                    # ì¶œíŒë¬¼ìœ í˜•
                    if 'ì¶œíŒë¬¼ìœ í˜•' in refs and refs['ì¶œíŒë¬¼ìœ í˜•']:
                        st.markdown("### ğŸ“‘ ì¶œíŒë¬¼ ìœ í˜•")
                        types = [t.strip() for t in refs['ì¶œíŒë¬¼ìœ í˜•'].strip().split('\n') if t.strip()]
                        types = [t[1:].strip() if t.startswith(('â€¢', '-', '*')) else t for t in types]
                        for pub_type in types:
                            if pub_type:
                                st.markdown(f"â€¢ {pub_type}")
                
                with col2:
                    # ì˜í–¥ë ¥ìˆëŠ”ì—°êµ¬ì
                    if 'ì˜í–¥ë ¥ìˆëŠ”ì—°êµ¬ì' in refs and refs['ì˜í–¥ë ¥ìˆëŠ”ì—°êµ¬ì']:
                        st.markdown("### ğŸ‘¨â€ğŸ”¬ ì˜í–¥ë ¥ ìˆëŠ” ì—°êµ¬ì")
                        researchers = [r.strip() for r in refs['ì˜í–¥ë ¥ìˆëŠ”ì—°êµ¬ì'].strip().split('\n') if r.strip()]
                        researchers = [r[1:].strip() if r.startswith(('â€¢', '-', '*')) else r for r in researchers]
                        for researcher in researchers[:5]:
                            if researcher:
                                st.markdown(f"â€¢ {researcher}")
                
                # ì‹œì‚¬ì 
                if 'ì‹œì‚¬ì ' in refs and refs['ì‹œì‚¬ì ']:
                    st.markdown("---")
                    st.markdown("### ğŸ’¡ ë¬¸í—Œ ë¶„ì„ ì‹œì‚¬ì ")
                    st.markdown(f"""<div style="padding: 15px; background-color: #e8f5e9; border-radius: 8px; border-left: 5px solid #4CAF50;">
                    {refs['ì‹œì‚¬ì ']}
                    </div>""", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
